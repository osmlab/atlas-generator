buildscript {
    dependencies {
        classpath 'com.diffplug.spotless:spotless-plugin-gradle:3.4.0'
    }
}

// Used to promote a staging release build
// https://github.com/Codearte/gradle-nexus-staging-plugin
// gradle closeAndReleaseRepository
plugins
{
    id "io.codearte.nexus-staging" version "0.8.0"
}

apply from: 'dependencies.gradle'
apply plugin: 'java'
apply plugin: 'checkstyle'
apply plugin: 'maven'
apply plugin: 'signing'
apply plugin: "com.diffplug.gradle.spotless"
apply plugin: 'idea'

sourceCompatibility=1.8
targetCompatibility=1.8

repositories
{
    // For geotools
    maven { url "http://download.osgeo.org/webdav/geotools/" }
    mavenCentral()
    // For Spark CDH
    maven { url "https://repository.cloudera.com/content/repositories/releases/" }
    // For jetty (through spark)
    maven { url "http://repo.spring.io/plugins-release/" }
}

idea {
    project {
        languageLevel = '1.8'
    }
}

spotless {
   java {
      importOrder(['static java', 'static javax', 'static org', 'static com', 'static scala', 'java', 'javax', 'org', 'com', 'scala'])
      removeUnusedImports()
      eclipse().configFile 'config/format/code_format.xml'
   }
}

// corresponds to POM description
description = "Atlas Library"

// This is to skip the tasks for which there is a skip<TaskName>=true environment variable
def skippedTaskNames = System.getenv().findAll { key, value ->
    key.startsWith("skip") && value.equalsIgnoreCase("true")
}.keySet().collect { it.substring(4) }

gradle.startParameter.excludedTaskNames += skippedTaskNames

checkstyle
{
    toolVersion = versions.checkstyle
}

sourceSets
{
    integrationTest
    {
        java
        {
            compileClasspath += main.output + test.output
            runtimeClasspath += main.output + test.output
            srcDir file('src/integrationTest/java')
        }
        resources.srcDir file('src/integrationTest/resources')
    }
}

test
{
    testLogging
    {
        events "passed", "skipped", "failed"
    }
}

configurations
{
    all
    {
        resolutionStrategy
        {
            force packages.atlas
            force packages.spark.core
            // http://stackoverflow.com/questions/31039367/spark-parallelize-could-not-find-creator-property-with-name-id
            // This is to avoid a JsonMappingException for something named 'id'
            // in org.apache.spark.rdd.RDDOperationScope
            force 'com.fasterxml.jackson.core:jackson-databind:2.4.4'
            // Snappy 1.1.1.6 is the one that has the proper .so libs.
            // https://github.com/xerial/snappy-java/issues/6
            force packages.snappy
        }
    }
    shaded
    {
        // Hadoop and Spark are way too fat.
        exclude group: 'org.apache.hadoop'
        exclude group: 'org.apache.spark'
    }
    integrationTestCompile.extendsFrom testCompile
    integrationTestRuntime.extendsFrom testRuntime
}

dependencies
{
    compile packages.atlas
    compile packages.spark.core
    
    shaded project.configurations.getByName('compile')
}

task integrationTest(type: Test) {
    testClassesDir = sourceSets.integrationTest.output.classesDir
    classpath = sourceSets.integrationTest.runtimeClasspath
    testLogging
    {
        events "passed", "skipped", "failed"
    }
}

check.dependsOn integrationTest
integrationTest.mustRunAfter test

tasks.withType(Test) {
    reports.html.destination = file("${reporting.baseDir}/${name}")
}

/**
 * Artifact related items
 */
task javadocJar(type: Jar) {
    classifier = 'javadoc'
    from javadoc
}

task sourcesJar(type: Jar) {
    classifier = 'sources'
    from sourceSets.main.allSource
}

task shaded(type: Jar){
    baseName = project.name
    classifier = 'shaded'
    from
    {
        configurations.shaded.collect
        {
            it.isDirectory() ? it : zipTree(it).matching{
                exclude
                {
                    it.path.contains('META-INF') && (it.path.endsWith('.SF') || it.path.endsWith('.DSA') || it.path.endsWith('.RSA'))
                }
            }
        }
    }
    with jar
    zip64 = true
}

task fat(type: Jar){
    baseName = project.name
    classifier = 'fat'
    from
    {
        configurations.compile.collect
        {
            it.isDirectory() ? it : zipTree(it).matching{
                exclude
                {
                    it.path.contains('META-INF') && (it.path.endsWith('.SF') || it.path.endsWith('.DSA') || it.path.endsWith('.RSA'))
                }
            }
        }
    }
    with jar
    zip64 = true
}

artifacts
{
    archives javadocJar, sourcesJar
}

/**
 * Deployment related items
 */
import org.gradle.plugins.signing.Sign

gradle.taskGraph.whenReady { taskGraph ->
    if (taskGraph.allTasks.any { it instanceof Sign }) {
        allprojects { ext."signing.keyId" = System.getenv('GPG_KEY_ID') }
        allprojects { ext."signing.secretKeyRingFile" = System.getenv('GPG_KEY_LOCATION') }
        allprojects { ext."signing.password" = System.getenv('GPG_PASSPHRASE') }
    }
    // Do not sign archives by default (a local build without gpg keyring should succeed)
    if (taskGraph.allTasks.any { it.name == 'build' || it.name == 'assemble' }) {
        tasks.findAll { it.name == 'signArchives' || it.name == 'signDocsJar' || it.name == 'signTestJar' }.each { task ->
            task.enabled = false
        }
    }
}

signing
{
    sign configurations.archives
}
build.dependsOn.remove(signArchives)

uploadArchives
{
    repositories
    {
        mavenDeployer
        {
            beforeDeployment
            {
                MavenDeployment deployment -> signing.signPom(deployment)
            }

            repository(url: maven2_url) {
                authentication(userName: System.getenv('SONATYPE_USERNAME'), password: System.getenv('SONATYPE_PASSWORD'))
            }

            snapshotRepository(url: snapshot_url) {
                authentication(userName: System.getenv('SONATYPE_USERNAME'), password: System.getenv('SONATYPE_PASSWORD'))
            }

            pom.project
            {
                name project_name
                packaging 'jar'
                // optionally artifactId can be defined here
                description project_description
                url project_url

                scm {
                    connection project_scm
                    developerConnection project_scm
                    url project_url
                }

                licenses {
                    license {
                        name project_license_slug
                        url project_license_url
                    }
                }

                developers {
                    developer {
                        id project_developer
                        name project_developer
                    }
                }
            }
        }
    }
}

